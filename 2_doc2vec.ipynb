{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util, scrape\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import collections\n",
    "import itertools\n",
    "import re\n",
    "import pickle\n",
    "import csv\n",
    "import multiprocessing\n",
    "import operator\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import seaborn as sns\n",
    "\n",
    "import gensim\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trip reports dataframe\n",
    "with open(util.TRIP_REPORTS_DATAFRAME_FILE, \"rb\") as f:\n",
    "    df = pickle.load(f)\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label docs individually by enumeration\n",
    "def label_docs(X):\n",
    "    labeled = []\n",
    "    for i, doc in enumerate(X):\n",
    "        labeled.append(gensim.models.doc2vec.TaggedDocument(words=doc, tags=[f\"DOC_{i}\"]))\n",
    "    return labeled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mask for dataframe columns to only include:\n",
    "# (1) top N drugs with the most trip reports \n",
    "# (2) trip reports with at least this many tokens to ensure informative content\n",
    "\n",
    "N = 10\n",
    "MIN_TOKENS = 30 \n",
    "\n",
    "mask_1 = [True if len(tokens) > MIN_TOKENS else False for tokens in df[\"trip_report_tokenized\"]]\n",
    "\n",
    "counter = collections.Counter(df[\"drug\"][mask_1])\n",
    "top_drugs = sorted(counter, key=lambda x: counter[x], reverse=True)[:N]\n",
    "mask_2 = [True if df[\"drug\"][i] in top_drugs else False for i, tokens in enumerate(df[\"trip_report_tokenized\"])]\n",
    "\n",
    "mask = np.logical_and(mask_1, mask_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_split_indices(y, train_size=0.8):\n",
    "    indices = [i for i in range(len(y))]\n",
    "    train_indices, test_indices, y_train, y_test = train_test_split(indices, y, train_size=train_size, stratify=y)\n",
    "    \n",
    "    return train_indices, test_indices\n",
    "    \n",
    "def split_X_into_train_test_sets(X, train_indices, test_indices):\n",
    "    X_train = X[train_indices, :]\n",
    "    X_test = X[test_indices, :]\n",
    "        \n",
    "    return X_train, X_test\n",
    "\n",
    "def split_y_into_train_test_sets(y, train_indices, test_indices):\n",
    "    y_train = [y[train_index] for train_index in train_indices]\n",
    "    y_test = [y[test_index] for test_index in test_indices]\n",
    "    \n",
    "    return y_train, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df[\"drug\"][mask])\n",
    "train_indices, test_indices = get_train_test_split_indices(y, train_size=0.8)\n",
    "y_train, y_test = split_y_into_train_test_sets(y, train_indices, test_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train doc2vec model by num_epochs\n",
    "def train_doc2vec_model(model, docs, num_epochs, lr_step, lr_min=0.0, verbose=True):\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        if verbose: print(f\"Epoch: {epoch}\")\n",
    "        model.train(docs, total_examples=model.corpus_count, epochs=1)\n",
    "        model.alpha -= lr_step  # decrease the learning rate\n",
    "        model.min_alpha = lr_min\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_doc2vec_models(vector_sizes, windows, lrs_and_lr_steps, training_session_epochs, num_training_sessions, dm=0):\n",
    "    # If dm=0, distributed bag of words (PV-DBOW) is used. \n",
    "    # If dm=1, ‘distributed memory’ (PV-DM) is used.\n",
    "    \n",
    "    num_hyperparam_configs = len(vector_sizes)*len(windows)*len(lrs_and_lr_steps)*num_training_sessions\n",
    "    num_hyperparam_configs_tried = 0\n",
    "\n",
    "    docs = label_docs(df[\"trip_report_tokenized\"][mask])\n",
    "\n",
    "    best_f_score_avg = 0.0\n",
    "    best_model = None\n",
    "    best_hyperparams = None\n",
    "    best_report = None\n",
    "    for vector_size, window, (lr, lr_step) in itertools.product(vector_sizes, windows, lrs_and_lr_steps):\n",
    "        model = gensim.models.doc2vec.Doc2Vec(docs, workers=multiprocessing.cpu_count(), dm=dm, vector_size=vector_size, window=window, alpha=lr, dm_concat=1)\n",
    "        epochs_trained = 0\n",
    "        for i in range(num_training_sessions):\n",
    "            train_doc2vec_model(model, docs, training_session_epochs, lr_step, verbose=False)\n",
    "            epochs_trained += training_session_epochs\n",
    "\n",
    "            # split X into train and test sets using established indices\n",
    "            X = np.array([model.docvecs[i] for i in range(len(model.docvecs))])\n",
    "            X_train, X_test = split_X_into_train_test_sets(X, train_indices, test_indices)\n",
    "\n",
    "            # train a simple Gaussian naive Bayes classifier whose test set predictions' average f_score \n",
    "            # will be the measure for a given doc2vec model's quality\n",
    "            clf = GaussianNB()\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            # test classifier \n",
    "            labels = np.unique(y_train)\n",
    "            report = util.test_classifier(clf, X_test, y_test, labels)\n",
    "            f_score_avg = np.mean(report[\"f_score\"])\n",
    "\n",
    "            # print progress\n",
    "            num_hyperparam_configs_tried += 1\n",
    "            print(f\"{num_hyperparam_configs_tried} / {num_hyperparam_configs} hyperparameter configurations tested: ({epochs_trained}, {vector_size}, {window}, {lr}, {lr_step})\")\n",
    "\n",
    "            # save best model\n",
    "            if f_score_avg >= best_f_score_avg:\n",
    "                best_f_score_avg = f_score_avg\n",
    "                best_model = copy.deepcopy(model)\n",
    "                best_hyperparams = (epochs_trained, vector_size, window, lr, lr_step)\n",
    "                best_report = report\n",
    "                print(f\"New best f-score average: {f_score_avg}\")\n",
    "\n",
    "    print(\"\\nDone\")\n",
    "\n",
    "    model = best_model\n",
    "    f_score_avg = best_f_score_avg\n",
    "    report = best_report\n",
    "    epochs_trained, vector_size, window, lr, lr_step = best_hyperparams\n",
    "    \n",
    "    hyperparams = {\n",
    "        \"epochs_trained\": epochs_trained,\n",
    "        \"vector_size\": vector_size,\n",
    "        \"window\": window,\n",
    "        \"lr\": lr,\n",
    "        \"lr_step\": lr_step\n",
    "    }\n",
    "\n",
    "    # print results\n",
    "    print(f\"\\nBest model: \")\n",
    "    print(f\"\\tF-score average: {f_score_avg}\")\n",
    "    if dm == 0:\n",
    "        print(\"\\tType of model: PV-DBOW\")\n",
    "    elif dm == 1:\n",
    "        print(\"\\tType of model: PV-DM\")\n",
    "    print(f\"\\tEpochs trained: {epochs_trained}\")\n",
    "    print(f\"\\tVector size: {vector_size}\")\n",
    "    print(f\"\\tWindow size: {window}\")\n",
    "    print(f\"\\tLearning rate: {lr}\")\n",
    "    print(f\"\\tLearning rate step decrease: {lr_step}\")\n",
    "    print(f\"\\tAverage F-score: {best_f_score_avg}\")\n",
    "    print(\"\\tClassification report:\\n\")\n",
    "    print(best_report)\n",
    "    print(\"\")\n",
    "    \n",
    "    return model, f_score_avg, report, hyperparams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_sizes = [50, 75, 100, 125, 150] \n",
    "windows = [3, 5, 7, 9] \n",
    "lrs_and_lr_steps = [\n",
    "    (2.0e-1, 0.0),\n",
    "    (2.0e-1, 2.0e-3),\n",
    "    (1.0e-1, 0.0),\n",
    "    (1.0e-1, 1.0e-3),\n",
    "    (7.5e-2, 0.0),\n",
    "    (7.5e-2, 7.5e-4),\n",
    "    (5.0e-2, 0.0),\n",
    "    (5.0e-2, 5.0e-4),\n",
    "    (2.5e-2, 0.0),\n",
    "    (2.5e-2, 2.5e-4),\n",
    "]\n",
    "\n",
    "training_session_epochs = 5\n",
    "num_training_sessions = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best PV-DBOW model \n",
    "model_dbow, f_score_avg_dbow, report_dbow, hyperparams_dbow = grid_search_doc2vec_models(vector_sizes, windows, lrs_and_lr_steps, training_session_epochs, num_training_sessions, dm=0)\n",
    "    \n",
    "# save PV-DM model\n",
    "with open(util.DOC2VEC_MODEL_DBOW_FILE, \"wb\") as f:\n",
    "    pickle.dump(model_dbow, f)\n",
    "    \n",
    "# save PV-DBOW hyperparameters\n",
    "with open(util.DOC2VEC_HYPERPARAMETERS_DBOW_FILE, \"wb\") as f:\n",
    "    pickle.dump(hyperparams_dbow, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best PV-DM model \n",
    "model_dm, f_score_avg_dm, report_dm, hyperparams_dm = grid_search_doc2vec_models(vector_sizes, windows, lrs_and_lr_steps, training_session_epochs, num_training_sessions, dm=1)\n",
    "\n",
    "# save PV-DM model\n",
    "with open(util.DOC2VEC_MODEL_DM_FILE, \"wb\") as f:\n",
    "    pickle.dump(model_dm, f)\n",
    "    \n",
    "# save PV-DM hyperparameters\n",
    "with open(util.DOC2VEC_HYPERPARAMETERS_DM_FILE, \"wb\") as f:\n",
    "    pickle.dump(hyperparams_dm, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the which model type (PV-DBOW or PV-DM) is best for classification\n",
    "model = None\n",
    "if f_score_avg_dbow > f_score_avg_dm:\n",
    "    model = model_dbow\n",
    "    print(\"Best model type: PV-DBOW\")\n",
    "else:\n",
    "    model = model_dm\n",
    "    print(\"Best model type: PV-DM\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model using t-SNE randomized algorithm\n",
    "X_projected = TSNE(metric='cosine', random_state=0).fit_transform(model.docvecs.vectors_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter(X, drugs_to_plot=drugs):\n",
    "    # make a custom color palette with seaborn\n",
    "    gray_palette = [[0.8, 0.8, 0.8]]\n",
    "    color_palette = sns.color_palette(\"hls\", len(drugs_to_plot))\n",
    "    palette = np.array(color_palette + gray_palette)\n",
    "    sns.palplot(palette)\n",
    "    \n",
    "    # get colors for selected classes\n",
    "    drug_to_rank_dict = {drug: i for i, drug in enumerate(drugs_to_plot)}\n",
    "    color_indices = np.array([np.int(drug_to_rank_dict[drug]) if drug in drugs_to_plot else -1 for drug in y])\n",
    "    color_index_to_drug_dict = {i: drug for i, drug in enumerate(drugs_to_plot)}\n",
    "\n",
    "    # We create a scatter plot.\n",
    "    f = plt.figure(figsize=(32, 32))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    sc = ax.scatter(X[:,0], X[:,1], lw=0, s=120,\n",
    "                    c=palette[color_indices])\n",
    "    #plt.xlim(-25, 25)\n",
    "    #plt.ylim(-25, 25)\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "\n",
    "    # We add the labels for each cluster.\n",
    "    \n",
    "    txts = []\n",
    "    for i, drug in enumerate(drugs_to_plot):\n",
    "        # Position of each label.\n",
    "        xtext, ytext = np.median(X[color_indices == i, :], axis=0)\n",
    "        txt = ax.text(xtext, ytext, color_index_to_drug_dict[i], fontsize=20)\n",
    "        txt.set_path_effects([\n",
    "            PathEffects.Stroke(linewidth=5, foreground=\"w\"),\n",
    "            PathEffects.Normal()])\n",
    "        txts.append(txt)\n",
    "    \n",
    "    return f, ax, sc, txts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(X_projected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs = sorted(np.unique(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for drug in drugs:\n",
    "    drugs_to_plot = [drug]\n",
    "    scatter(X_projected, drugs_to_plot)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
