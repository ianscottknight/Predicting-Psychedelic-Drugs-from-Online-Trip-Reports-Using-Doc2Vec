{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util, scrape\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import collections\n",
    "import itertools\n",
    "import re\n",
    "import pickle\n",
    "import csv\n",
    "import multiprocessing\n",
    "import operator\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import seaborn as sns\n",
    "\n",
    "import gensim\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trip reports dataframe\n",
    "with open(util.TRIP_REPORTS_DATAFRAME_FILE, \"rb\") as f:\n",
    "    df = pickle.load(f)\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label docs individually by enumeration\n",
    "def label_docs(X):\n",
    "    labeled = []\n",
    "    for i, doc in enumerate(X):\n",
    "        labeled.append(gensim.models.doc2vec.TaggedDocument(words=doc, tags=[f\"DOC_{i}\"]))\n",
    "    return labeled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mask for dataframe columns to only include:\n",
    "# (1) top N drugs with the most trip reports \n",
    "# (2) trip reports with at least this many tokens to ensure informative content\n",
    "\n",
    "N = 10 \n",
    "MIN_TOKENS = 30 \n",
    "\n",
    "counter = collections.Counter(df[\"drug\"])\n",
    "top_drugs = sorted(counter, key=lambda x: counter[x], reverse=True)[:N]\n",
    "\n",
    "mask = [True if (len(tokens) > MIN_TOKENS) and (df[\"drug\"][i] in top_drugs) else False for i, tokens in enumerate(df[\"trip_report_tokenized\"])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_split_indices(X, y, train_size=0.8):\n",
    "    indices = [i for i in range(len(X))]\n",
    "    train_indices, test_indices, y_train, y_test = train_test_split(indices, y, train_size=train_size, stratify=y)\n",
    "    \n",
    "    return train_indices, test_indices\n",
    "    \n",
    "def split_X_into_train_test_sets(X, train_indices, test_indices):\n",
    "    X_train = np.zeros((len(train_indices), model.vector_size))\n",
    "    X_test = np.zeros((len(test_indices), model.vector_size))\n",
    "    for i, train_index in enumerate(train_indices):\n",
    "        X_train[i] = X[train_index]\n",
    "    for i, test_index in enumerate(test_indices):\n",
    "        X_test[i] = X[test_index]\n",
    "        \n",
    "    return X_train, X_test\n",
    "\n",
    "def split_y_into_train_test_sets(y, train_indices, test_indices):\n",
    "    y_train = [y[train_index] for train_index in train_indices]\n",
    "    y_test = [y[test_index] for test_index in test_indices]\n",
    "    \n",
    "    return y_train, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, test_indices = get_train_test_split_indices(X, y, train_size=0.8)\n",
    "y = df[\"drug\"][mask]\n",
    "y_train, y_test = split_y_into_train_test_sets(y, train_indices, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train doc2vec model by num_epochs\n",
    "def train_doc2vec_model(model, docs, num_epochs, lr_step, lr_min=0.0, verbose=True):\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        if verbose: print(f\"Epoch: {epoch}\")\n",
    "        model.train(docs, total_examples=model.corpus_count, epochs=1)\n",
    "        model.alpha -= lr_step  # decrease the learning rate\n",
    "        model.min_alpha = lr_min\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test given classifier on test set\n",
    "def test_classifier(clf, X_test, y_test, labels, top_n=3, show_top_n_accuracy=False, show_confusion_matrix=False):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    precision, recall, f_score, support = precision_recall_fscore_support(y_test, y_pred, labels=labels, average=None)\n",
    "    report = pd.DataFrame({\n",
    "        \"class\": labels,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f_score\": f_score,\n",
    "        \"support\": support\n",
    "    })\n",
    "    \n",
    "    if show_top_n_accuracy:\n",
    "        y_hat = clf.predict_proba(X_test)\n",
    "        classes = clf.classes_\n",
    "        y_pred_sorted = []\n",
    "        y_hat_sorted = []\n",
    "        num_correct = 0\n",
    "        for i, probs in enumerate(y_hat):\n",
    "            probs_sorted, classes_sorted = (list(l) for l in zip(*sorted(zip(probs, classes), key=operator.itemgetter(0), reverse=True)))\n",
    "            true_class = y_test.iloc[i]\n",
    "            top_classes = classes_sorted[:top_n]\n",
    "            top_probs = probs_sorted[:top_n]\n",
    "            y_pred_sorted.append(classes_sorted)\n",
    "            y_hat_sorted.append(probs_sorted)\n",
    "            if true_class in top_classes:\n",
    "                num_correct += 1\n",
    "        top_n_acc = num_correct / len(y_pred)\n",
    "        print(f\"Top-{top_n} accuracy: {top_n_acc}\")\n",
    "    \n",
    "    if show_confusion_matrix:\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        new_cm = []\n",
    "        for row in cm:\n",
    "            support = sum(row)\n",
    "            new_row = row / support\n",
    "            new_cm.append(new_row)\n",
    "        cm = new_cm\n",
    "\n",
    "        df_cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "        plt.figure(figsize=(20,20))\n",
    "        ax = sns.heatmap(df_cm, annot=False, linewidth=0.05)\n",
    "        bottom, top = ax.get_ylim()\n",
    "        ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "        \n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_sizes = [64, 128] \n",
    "windows = [3, 5, 7, 9] \n",
    "lrs = [7.5e-2, 2.5e-2, 7.5e-3]\n",
    "lr_steps = [1.0e-3, 3.0e-3, 5.0e-5, 0.0]\n",
    "\n",
    "docs = label_docs(df[\"trip_report_tokenized\"][mask])\n",
    "\n",
    "best_f_score_avg = 0.0\n",
    "best_model = None\n",
    "best_hyperparams = None\n",
    "best_report = None\n",
    "for vector_size, window, lr, lr_step in itertools.product(vector_sizes, windows, lrs, lr_steps):\n",
    "    # If dm=1, ‘distributed memory’ (PV-DM) is used. Otherwise, distributed bag of words (PV-DBOW) is employed.\n",
    "    model = gensim.models.doc2vec.Doc2Vec(docs, workers=multiprocessing.cpu_count(), dm=0, vector_size=vector_size, window=window, alpha=lr, min_alpha=lr_min)\n",
    "    epochs_step = 5\n",
    "    epochs_trained = 0\n",
    "    for i in range(10):\n",
    "        train_doc2vec_model(model, docs, epochs_step, lr_step)\n",
    "        epochs_trained += epochs_step\n",
    "    \n",
    "        # split X into train and test sets using established indices\n",
    "        X = model.docvecs\n",
    "        X_train, X_test = split_X_into_train_test_sets(X, train_indices, test_indices)\n",
    "        \n",
    "        # train classifier\n",
    "        clf = GaussianNB()\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        # test classifier and save best model\n",
    "        labels = np.unique(y_train)\n",
    "        report = test_classifier(clf, X_test, y_test, labels)\n",
    "        f_score_avg = np.mean(report[\"f_score\"])\n",
    "        if f_score_avg >= best_f_score_avg:\n",
    "            best_f_score_avg = f_score_avg\n",
    "            best_model = copy.deepcopy(model)\n",
    "            best_hyperparams = (epochs_trained, vector_size, window, lr, lr_step)\n",
    "            best_report = report\n",
    "\n",
    "print(f\"Best model: \")\n",
    "print(f\"\\tEpochs trained: {epochs_trained}\")\n",
    "print(f\"\\tVector size: {vector_size}\")\n",
    "print(f\"\\tWindow size: {window}\")\n",
    "print(f\"\\tLearning rate: {lr}\")\n",
    "print(f\"\\tLearning rate step decrease: {lr_step}\")\n",
    "print(f\"\\tAverage F-score: {best_f_score_avg}\")\n",
    "print(\"\\tClassification report:\\n\")\n",
    "print(best_report)\n",
    "print(\"\")\n",
    "\n",
    "model = best_model\n",
    "epochs_trained, vector_size, window, lr, lr_step = best_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model\n",
    "with open(util.DOC2VEC_MODEL_FILE, \"wb\") as f:\n",
    "    pickle.dump(best_model, f)\n",
    "    \n",
    "# save best hyperparameters\n",
    "with open(util.DOC2VEC_HYPERPARAMETERS_FILE, \"w\") as f:\n",
    "    \n",
    "    f.write(f\"Epochs trained: {epochs_trained}\\n\")\n",
    "    f.write(f\"Vector size: {vector_size}\\n\")\n",
    "    f.write(f\"Window size: {window}\\n\")\n",
    "    f.write(f\"Learning rate: {lr}\\n\")\n",
    "    f.write(f\"Learning rate step decrease: {lr_step}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run grid search on classifiers and provided parameters and return the best result\n",
    "def grid_search_classifiers(X_train, X_test, y_train, y_test, clfs, clf_to_gs_params_dict, cv=5):\n",
    "    reports = []\n",
    "    f_score_avgs = []\n",
    "    for clf in clfs:\n",
    "        print(f\"\\tTraining classifier: {clf.__class__}...\")\n",
    "        gs = GridSearchCV(clf, clf_to_gs_params_dict[clf.__class__], cv=cv)\n",
    "        gs.fit(X_train, y_train)\n",
    "        labels = np.unique(y_train)\n",
    "        report = test_classifier(gs, X_test, y_test, labels)\n",
    "        reports.append(report)\n",
    "        f_score_avg = np.mean(report[\"f_score\"])\n",
    "        f_score_avgs.append(f_score_avg)\n",
    "        \n",
    "    results_sorted = sorted(zip(clfs, f_score_avgs, reports), key=lambda x: x[1], reverse=True)\n",
    "    best_result = results_sorted[0]\n",
    "            \n",
    "    return best_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run grid search wrapped in a k-fold\n",
    "def grid_search_classifiers_k_fold(X, y, clfs, clf_to_gs_params_dict, k_fold=10):\n",
    "\n",
    "    results = []\n",
    "    skf = StratifiedKFold(n_splits=k_fold)\n",
    "    train_test_split_indices = skf.split(X, y)\n",
    "    \n",
    "    for i, (train_indices, test_indices) in enumerate(train_test_split_indices):\n",
    "\n",
    "        X_train, X_test = X[train_indices], X[test_indices]\n",
    "        y_train, y_test = y[train_indices], y[test_indices]\n",
    "        \n",
    "        result = grid_search_classifiers(X_train, X_test, y_train, y_test, clfs, clf_to_gs_params_dict)\n",
    "        results.append(result)\n",
    "        \n",
    "    return all_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = [\n",
    "    GaussianNB(),\n",
    "    LogisticRegression(),\n",
    "    KNeighborsClassifier(),\n",
    "    SVC(probability=True),\n",
    "    MLPClassifier()\n",
    "]\n",
    "\n",
    "clf_to_gs_params_dict = {\n",
    "    GaussianNB().__class__: {\n",
    "    },\n",
    "    LogisticRegression().__class__: {\n",
    "        \"penalty\": (\"l1\", \"l2\"),\n",
    "        \"C\": (1.0e0, 1.0e-1, 1.0e-2, 1.0e-3, 1.0e-4, 1.0e-5)\n",
    "    },\n",
    "    KNeighborsClassifier().__class__: {\n",
    "        \"n_neighbors\": (4, 8, 12)\n",
    "    },\n",
    "    SVC().__class__: {\n",
    "        \"kernel\": (\"rbf\", \"poly\"),\n",
    "        \"gamma\": (1.0e0, 1.0e1, 1.0e2, 1.0e3),\n",
    "        \"degree\": (2, 4, 6)\n",
    "        \n",
    "    },\n",
    "    MLPClassifier().__class__: {\n",
    "        \"alpha\": (1.0e-3, 1.0e-4, 1.0e-5),\n",
    "        \"batch_size\": (8, 16, 64),\n",
    "        \"learning_rate\": (\"constant\", \"adaptive\"),\n",
    "        \"learning_rate_init\": (1.0e-2, 1.0e-3, 1.0e-4),\n",
    "        \"tol\": (1e-3, 1e-4, 1e-4),\n",
    "        \"early_stopping\": (True),\n",
    "        \"momentum\": (0.5, 0.9),\n",
    "    }\n",
    "}\n",
    "\n",
    "# split X into train and test sets using established indices\n",
    "X = model.docvecs\n",
    "X_train, X_test = split_X_into_train_test_sets(X, train_indices, test_indices)\n",
    "\n",
    "best_clf, best_f_score_avg, best_report = grid_search_classifiers(X_train, X_test, y_train, y_test, clfs, clf_to_gs_params_dict)\n",
    "print(f\"\\tBest classifier: {best_clf}\")\n",
    "print(f\"\\tAverage F-score: {best_f_score_avg}\")\n",
    "print(\"\\tClassification report:\\n\")\n",
    "print(best_report)\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs = sorted(np.unique(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model using t-SNE randomized algorithm\n",
    "X_projected = TSNE(random_state=0).fit_transform(model.docvecs.vectors_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter(X, drugs_to_plot=drugs):\n",
    "    # make a custom color palette with seaborn\n",
    "    gray_palette = [[0.8, 0.8, 0.8]]\n",
    "    color_palette = sns.color_palette(\"hls\", len(drugs_to_plot))\n",
    "    palette = np.array(color_palette + gray_palette)\n",
    "    sns.palplot(palette)\n",
    "    \n",
    "    # get colors for selected classes\n",
    "    drug_to_rank_dict = {drug: i for i, drug in enumerate(drugs_to_plot)}\n",
    "    color_indices = np.array([np.int(drug_to_rank_dict[drug]) if drug in drugs_to_plot else -1 for drug in y])\n",
    "    color_index_to_drug_dict = {i: drug for i, drug in enumerate(drugs_to_plot)}\n",
    "\n",
    "    # We create a scatter plot.\n",
    "    f = plt.figure(figsize=(32, 32))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    sc = ax.scatter(X[:,0], X[:,1], lw=0, s=120,\n",
    "                    c=palette[color_indices])\n",
    "    #plt.xlim(-25, 25)\n",
    "    #plt.ylim(-25, 25)\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "\n",
    "    # We add the labels for each cluster.\n",
    "    \n",
    "    txts = []\n",
    "    for i, drug in enumerate(drugs_to_plot):\n",
    "        # Position of each label.\n",
    "        xtext, ytext = np.median(X[color_indices == i, :], axis=0)\n",
    "        txt = ax.text(xtext, ytext, color_index_to_drug_dict[i], fontsize=20)\n",
    "        txt.set_path_effects([\n",
    "            PathEffects.Stroke(linewidth=5, foreground=\"w\"),\n",
    "            PathEffects.Normal()])\n",
    "        txts.append(txt)\n",
    "    \n",
    "    return f, ax, sc, txts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(X_projected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for drug in drugs:\n",
    "    drugs_to_plot = [drug]\n",
    "    scatter(X_projected, drugs_to_plot)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get average doc vec\n",
    "avg_doc_vec = np.mean([model.docvecs[i] for i in range(len(model.docvecs))], axis=0)\n",
    "\n",
    "# accumulate doc vecs for each drug in a dictionary\n",
    "drug_to_doc_vecs_dict = collections.defaultdict(list)\n",
    "for i, drug in enumerate(df[\"drug\"]):\n",
    "    doc_tag = f\"DOC_{i}\"\n",
    "    doc_vec = model.docvecs[doc_tag]\n",
    "    drug_to_doc_vecs_dict[drug].append(doc_vec)\n",
    "    \n",
    "# assign a psych vec for each psychedelic by taking adding the difference between the mean of the drug's doc vecs \n",
    "# and the average doc vec to the mean of the drug's doc vecs, in order to produce a vector that is more extreme in\n",
    "# the ways that the drug's average doc vec is already extreme, so as to highlight what makes it distinct from the \n",
    "# other drug's average doc vec\n",
    "SIGMA = 0\n",
    "drug_to_psych_vec_dict = {drug : np.mean(doc_vecs, axis=0) + ((np.mean(doc_vecs, axis=0) - avg_doc_vec) * SIGMA) for drug, doc_vecs in drug_to_doc_vecs_dict.items()}\n",
    "\n",
    "# print the words whose vectors are closest to each psych vec\n",
    "for drug, psych_vec in drug_to_psych_vec_dict.items():\n",
    "    print(drug+'\\n', model.wv.most_similar([psych_vec]), '\\n')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
