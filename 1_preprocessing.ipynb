{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util, scrape\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import collections\n",
    "import itertools\n",
    "import re\n",
    "import pickle\n",
    "import csv\n",
    "import multiprocessing\n",
    "import operator\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trip reports dataframe of all drugs with at least MIN_NUM_TRIP_REPORTS trip reports\n",
    "\n",
    "MIN_NUM_TRIP_REPORTS = 10\n",
    "\n",
    "df = pd.read_csv(util.TRIP_REPORTS_FILE)\n",
    "\n",
    "drug_to_trip_reports_count_dict = dict(sorted(collections.Counter(df[\"drug\"]).items(), key=lambda x: x[1]))\n",
    "drugs_to_ignore = [drug for drug, count in drug_to_trip_reports_count_dict.items() if count < MIN_NUM_TRIP_REPORTS]\n",
    "\n",
    "for drug_to_ignore in drugs_to_ignore:\n",
    "    df = df[df.drug != drug_to_ignore]\n",
    "    \n",
    "df = df.sample(frac=1)\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drug</th>\n",
       "      <th>trip_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSD</td>\n",
       "      <td>During the Summer of 2004 I experienced what I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2CD</td>\n",
       "      <td>This is a report about my first time trying 2C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMT</td>\n",
       "      <td>It was the start of Superbowl Weekand, and I w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Morning_Glory</td>\n",
       "      <td>I’ve always heard how Morning Glory seeds can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2CE</td>\n",
       "      <td>Background: I am male, at the time of this exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5592</th>\n",
       "      <td>LSD</td>\n",
       "      <td>To start off I would consider myself a very ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5593</th>\n",
       "      <td>Salvia_divinorum</td>\n",
       "      <td>I was home alone in my little apartment in Lon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5594</th>\n",
       "      <td>2CT21</td>\n",
       "      <td>Setting: Alone on a weekday evening. My comfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5595</th>\n",
       "      <td>LSD</td>\n",
       "      <td>It started off as a harmless birthday party. M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5596</th>\n",
       "      <td>Mushrooms</td>\n",
       "      <td>My experiance began one month ago.  After a he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5597 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  drug                                        trip_report\n",
       "0                  LSD  During the Summer of 2004 I experienced what I...\n",
       "1                  2CD  This is a report about my first time trying 2C...\n",
       "2                  AMT  It was the start of Superbowl Weekand, and I w...\n",
       "3        Morning_Glory  I’ve always heard how Morning Glory seeds can ...\n",
       "4                  2CE  Background: I am male, at the time of this exp...\n",
       "...                ...                                                ...\n",
       "5592               LSD  To start off I would consider myself a very ex...\n",
       "5593  Salvia_divinorum  I was home alone in my little apartment in Lon...\n",
       "5594             2CT21  Setting: Alone on a weekday evening. My comfor...\n",
       "5595               LSD  It started off as a harmless birthday party. M...\n",
       "5596         Mushrooms  My experiance began one month ago.  After a he...\n",
       "\n",
       "[5597 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e8500aafcc1449c8be88f7e80ad08b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5597), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# remove square brackets and their contents (messages left by erowid administrators)\n",
    "def preprocess(text):\n",
    "    brackets = re.findall(re.compile(\"\\(.*?\\)\"), text)\n",
    "    for b in brackets:\n",
    "        names_text = text.replace(b, \" \")\n",
    "    \n",
    "    # remove zero-width space \n",
    "    text = text.replace(\"\\u200b\", \" \")\n",
    "    \n",
    "    return text\n",
    "\n",
    "# apply\n",
    "preprocessed = df[\"trip_report\"].progress_apply(preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e984e61de4754b508df8cf714b583a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5597), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# run spacy pipeline (spacy is an NLP library) with added custom component\n",
    "\n",
    "# treat multi-word entities as individual tokens instead of multiple tokens\n",
    "class EntityRetokenizeComponent:\n",
    "    def __init__(self, pipeline):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, doc):\n",
    "        with doc.retokenize() as retokenizer:\n",
    "            for ent in doc.ents:\n",
    "                retokenizer.merge(doc[ent.start:ent.end], attrs={\"LEMMA\": str(doc[ent.start:ent.end])})\n",
    "        return doc\n",
    "\n",
    "# create spacy pipeline\n",
    "spacy_pipeline = spacy.load('en')\n",
    "retokenizer = EntityRetokenizeComponent(spacy_pipeline) \n",
    "spacy_pipeline.add_pipe(retokenizer, name='merge_enitities', last=True)\n",
    "\n",
    "# apply\n",
    "df[\"trip_report_spacy\"] = preprocessed.progress_apply(spacy_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load custom stop words from file\n",
    "custom_stop_words = []\n",
    "with open(util.CUSTOM_STOP_WORDS_FILE) as f:\n",
    "    custom_stop_words = f.readlines()\n",
    "custom_stop_words = [w.strip() for w in custom_stop_words]\n",
    "\n",
    "# augment custom stop words (e.g. add \"pre-\", \"post-\", \"-esque\", \"-type\" to each word)\n",
    "custom_stop_words = scrape.augment_custom_stop_words()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "199ed39c02fb4e7d8eec53b61827f15c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5597), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# tokenize trip reports using spacy docs\n",
    "\n",
    "def tokenize(doc):\n",
    "    tokens = []\n",
    "    for w in doc.doc:\n",
    "        if all([\n",
    "            (w.is_alpha),\n",
    "            (w.lang_ == 'en'),\n",
    "            (w.is_ascii),\n",
    "            (not spacy_pipeline.vocab[w.text.lower()].is_stop),\n",
    "            (w.text.lower() not in custom_stop_words),\n",
    "            (w.lemma_ not in custom_stop_words),\n",
    "            (not w.is_space), \n",
    "            (not w.is_punct),\n",
    "            (not w.is_digit),\n",
    "            (w.ent_type == 0),\n",
    "            (w.lemma_ != \"\")\n",
    "        ]):\n",
    "            tokens.append(str(w.lemma_))\n",
    "    return tokens\n",
    "\n",
    "tokenized = df[\"trip_report_spacy\"].progress_apply(tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ea9f3ce6cf848c4bdcbbdfae862211f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5597), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# filter out words that appear less than MIN_WORD_COUNT times in the entire corpus \n",
    "\n",
    "MIN_WORD_COUNT = 10\n",
    "\n",
    "vocabulary = []\n",
    "for tokens in tokenized:\n",
    "    vocabulary += tokens\n",
    "word_count_dict = dict(sorted(collections.Counter(vocabulary).items(), key=lambda x: x[1], reverse=True))\n",
    "vocabulary = set([w for w in word_count_dict if word_count_dict[w] >= MIN_WORD_COUNT])\n",
    "\n",
    "def filter_uncommon_words(tokens):\n",
    "    return [str(token) for token in tokens if token in vocabulary]\n",
    "\n",
    "# apply\n",
    "df[\"trip_report_tokenized\"] = tokenized.progress_apply(filter_uncommon_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocobulary size: 9712\n"
     ]
    }
   ],
   "source": [
    "# size of vocabulary\n",
    "print(f\"Vocobulary size: {len(vocabulary)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove spacy column from dataframe so that we can efficiently save it to memory\n",
    "del df[\"trip_report_spacy\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trip reports dataframe \n",
    "with open(util.TRIP_REPORTS_DATAFRAME_FILE, \"wb\") as f:\n",
    "    pickle.dump(df, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
